###################################################
#
# Author
# ------
# Davide Borra, 2021
###################################################
seed: 2602
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# DIRECTORIES
data_folder: !PLACEHOLDER  #'/path/to/MOABB_BNCI2014001'
output_folder: '/home/fpaissan/code/speechbrain-1/recipes/MOABB/MotorImagery_decoding/BNCI2014001/results' #!ref results/MOABB_BNCI2014001/<seed>

# DATASET HPARS
C: 22
# Target sampling rate while downsampling
sf: 128
# tmin, tmax respect to stimulus onset to define EEG epochs
tmin: 0.5
tmax: 2.5
# fmin, fmax band-pass filtering
fmin: 4
fmax: 40
# Time samples=int((tmax-tmin)*sf)
T: 256

# TRAINING HPARS
nfolds: 5
valid_ratio: 0.2
number_of_epochs: 500 # number of training epochs
max_increase_epochs: 50  # early stop when after consecutive "max_increase_epochs" epochs there is no improvement
num_warmup_epochs: 5  # start checking for early stopping after first "num_warmup_epochs"
target_valid_metric: 'f1'  # target metric to track while performing early stopping
direction: 'max'  # direction to optimize the target metric
batch_size: 32
lr: 0.001
loss: !name:torch.nn.functional.nll_loss
class_weight: [1, 1, 1, 1]  # class weight to address class imbalance
optimizer: !name:torch.optim.Adam
  lr: !ref <lr>
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounterWithStopper  # epoch counter and early stopper
  limit: !ref <number_of_epochs>
  limit_to_stop: !ref <max_increase_epochs>
  limit_warmup: !ref <num_warmup_epochs>
  direction: !ref <direction>


# EEGNET HPARS
k0: 8  # number of temporal filters in the temporal conv. layer
d1: 2  # depth multiplier for the spatial depthwise conv. layer
k3: !ref <k0> * <d1>  # number of spatial depthwise filters
f0: 33  # length of temporal filters in the temporal conv. layer
f2: 17  # length of temporal filters in the temporal separable conv. layer
fp0: 4  # temporal pool size and stride of the first pooling layer
fp1: 8  # temporal pool size and stride of the second pooling layer
fptot: !ref <fp0> * <fp1>  # overall pool size
max_norm_1: 1.  # kernel max-norm constaint of the spatial depthwise conv. layer
max_norm_out: 0.25  # kernel max-norm constaint of the dense layer
p_drop: 0.5  # dropout rate
padding_mode: 'constant'

layer0: !new:speechbrain.nnet.CNN.Conv2d
  in_channels: 1
  out_channels: !ref <k0>
  kernel_size: [!ref <f0>, 1]
  padding: 'same'
  padding_mode: !ref <padding_mode>
  bias: False
bnorm0: !new:speechbrain.nnet.normalization.BatchNorm2d
  input_size: !ref <k0>
  momentum: 0.01
  affine: True

layer1: !new:speechbrain.nnet.CNN.Conv2dWithConstraint
  in_channels: !ref <k0>
  out_channels: !ref <k0> * <d1>
  kernel_size: [1, !ref <C>]
  groups: !ref <k0>
  max_norm: !ref <max_norm_1>
  padding: 'valid'
  bias: False
bnorm1: !new:speechbrain.nnet.normalization.BatchNorm2d
  input_size: !ref <k0> * <d1>
  momentum: 0.01
  affine: True
avgpool1: !new:speechbrain.nnet.pooling.Pooling2d
  pool_type: 'avg'
  kernel_size: [!ref <fp0>, 1]
  stride: [!ref <fp0>, 1]
  pool_axis: [2, 3]

layer2: !new:speechbrain.nnet.CNN.Conv2d
  in_channels: !ref <k0> * <d1>
  out_channels: !ref <k0> * <d1>
  kernel_size: [!ref <f2>, 1]
  padding: 'same'
  padding_mode: !ref <padding_mode>
  groups: !ref <k0> * 2
  bias: False
layer3: !new:speechbrain.nnet.CNN.Conv2d
  in_channels: !ref <k0> * <d1>
  out_channels: !ref <k3>
  kernel_size: [1, 1]
  padding: 'valid'
  bias: False
bnorm3: !new:speechbrain.nnet.normalization.BatchNorm2d
  input_size: !ref <k3>
  momentum: 0.01
  affine: True
avgpool3: !new:speechbrain.nnet.pooling.Pooling2d
  pool_type: 'avg'
  kernel_size: [!ref <fp1>, 1]
  stride: [!ref <fp1>, 1]
  pool_axis: [2, 3]

layer4: !new:speechbrain.nnet.linear.LinearWithConstraint
  input_size: !ref <k3> * <T> // <fptot>
  n_neurons: 4  # 4 output neurons
  max_norm: !ref <max_norm_out>
  bias: True

model: !new:speechbrain.nnet.containers.Sequential
  - !ref <layer0>
  - !ref <bnorm0>

  - !ref <layer1>
  - !ref <bnorm1>
  - !ref <avgpool1>
  - !new:torch.nn.Dropout
    p: !ref <p_drop>
  - !new:torch.nn.ELU

  - !ref <layer2>
  - !ref <layer3>
  - !ref <bnorm3>
  - !ref <avgpool3>
  - !new:torch.nn.Dropout
    p: !ref <p_drop>
  - !new:torch.nn.ELU

  - !new:torch.nn.Flatten
  - !ref <layer4>
  - !new:torch.nn.LogSoftmax
    dim: 1
